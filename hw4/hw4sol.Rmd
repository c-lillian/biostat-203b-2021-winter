---
title: "Biostat 203B Homework 4"
subtitle: Due Mar 12 @ 11:59PM
output:
  html_document:
    toc: true
    toc_depth: 4
  # ioslides_presentation: default
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```
                      
Display machine information:

```{r}
sessionInfo()
```

Load database libraries and the tidyverse frontend:

```{r, echo = T, include = F, eval = T}

library(tidyverse)
library(lubridate)
library(miceRanger)
library(data.table)
library(splitTools)
library(ranger)
library(Metrics)
library(randomForest)

```

## Q1. Missing data

Through the Shiny app developed in HW3, we observe abundant missing values in the MIMIC-IV ICU cohort we created. In this question, we use multiple imputation to obtain a data set without missing values.

0. Read following tutorials on the R package miceRanger for imputation: <https://github.com/farrellday/miceRanger>, <https://cran.r-project.org/web/packages/miceRanger/vignettes/miceAlgorithm.html>.

    A more thorough book treatment of the practical imputation strategies is the book [*_Flexible Imputation of Missing Data_*](https://stefvanbuuren.name/fimd/) by Stef van Buuren. 

1. Explain the jargon MCAR, MAR, and MNAR.

**Solution**:

MCAR stands for Missing Completely At Random. A variable is missing completely at random if neither the variables in the dataset nor the unobserved value of the variable itself predict whether a value will be missing. In other words, the causes of missing data are unrelated to the data.

MAR stands for Missing at Random. A variable is missing at random if other variables in the dataset can be used to predict the missingness of the variable. In other words, the probability of missingness is the same only within groups defined by the observed data. Most modern missing data methods start from the MAR assumption.

MNAR stands for Missing Not at Random. A variable is missing not at random if the value of the unobserved variable itself predicts missingness. MNAR is the most complex case as the causes for the missingness vary for reasons unknown to the investigator.


2. Explain in a couple of sentences how the Multiple Imputation by Chained Equations (MICE) work.

**Solution**:

Multiple Imputation by Chained Equations (MICE) works by creating multiple imputations to account for statistical uncertainty in the imputations, and utilizing a chained equations approach to allow for flexibility with handling variables of different types. Using the MICE technique assumes that for the variables used in the imputation procedure, the missing data are MAR. If this assumption is not met, then there could be biased estimates when MICE is implemented.

The chained equation process involves 1) an imputation performed for every missing value in the data set, 2) placeholder imputations for one variable are set back to missing, 3) observed values from that one variable are regressed on other variables in the data set, with the one variable as the outcome variable, 4) missing values for that one variable are replaced with the imputations from the regression model if it is used as an outcome, and both observed and imputed values will be used if the variable is used as a predictor. The process is repeated for all the variables to complete one iteration/cycle. For later cycles, imputations are updated at each subsequent cycle. The accuracy of the imputations depends on the information density in the dataset. A dataset of completely independent variables with no correlation will not yield accurate imputations.


3. Perform a data quality check of the ICU stays data. Discard variables with substantial missingness, say >5000 `NA`s. Replace apparent data entry errors by `NA`s.

**Solution**:

```{r Q3 data quality check}
icu_cohort <- readRDS("./icu_cohort.rds")

sapply(icu_cohort, function(x) sum(is.na(x)))

# discarding variables with substantial missingness
icu_cohort2 <- icu_cohort %>% 
  dplyr::select(-deathtime, -edregtime, -edouttime, -dod, 
         -arterial_blood_pressure_systolic, -arterial_blood_pressure_mean,
         -lactate)


```
I utilized sapply to identify missing values and distribution of values in the dataset. This allowed to identify patients with abnormal values such as a heart rate of 0 when the patient survived and had normal bp measurements for the other columns. I re-ran these built-in functions as necessary to identify data entry errors and filtered them out in the subsequent code chunk.

```{r Q3 unique values, eval = F}

sapply(icu_cohort2[,4:5], unique)
sapply(icu_cohort2[,11:19], unique)
sapply(icu_cohort2[,24:38], unique)
sapply(icu_cohort2[,24:38], summary)
```
Here, I filter out apparent data entry errors. I remained fairly conservative in my removal of abnormal data values, and primarily focused on 0s in the data when other columns appeared to have normal values, and also focused on possible scale conversion errors with Fahrenheit/Celsius that may have been recorded under the Fahrenheit column of the original data set.

```{r Q3 replacement of apparent data entry errors}

# replace 0s with NAs for heart rate, non invasive bp (systolic and mean),
# respiratory rate, temperature in Fahrenheit
icu_cohort2[, 24:28][icu_cohort2[, 24:28] == 0] = NA

# replace 0s with NAs for calcium, creatinine, magnesium, and wbc
icu_cohort2$calcium[icu_cohort2$calcium == 0] = NA
icu_cohort2$creatinine[icu_cohort2$creatinine == 0] = NA
icu_cohort2$magnesium[icu_cohort2$magnesium == 0] = NA
icu_cohort2$wbc[icu_cohort2$wbc == 0] = NA


# replace with NA if blood pressure values were less than 2
icu_cohort2[, 25:26][icu_cohort2[, 25:26] < 2] = NA

# replace with NA if blood pressure values were substantially abnormal
icu_cohort2 <- icu_cohort2 %>% 
  mutate(non_invasive_blood_pressure_systolic = ifelse(
      (non_invasive_blood_pressure_systolic > 300) | 
        (non_invasive_blood_pressure_systolic < 10), NA, 
      non_invasive_blood_pressure_systolic),
    non_invasive_blood_pressure_mean = ifelse(
      non_invasive_blood_pressure_mean > 300 | 
        (non_invasive_blood_pressure_mean < 10), NA,
      non_invasive_blood_pressure_mean),
    # replace with NA if heart rate values were substantially abnormal
    heart_rate = ifelse(heart_rate > 300, NA, heart_rate)
  )


# replace with NA if temperature in Fahrenheit was less than 60
icu_cohort2$temperature_fahrenheit[icu_cohort2$temperature_fahrenheit < 60] = NA

# Check NAs
sapply(icu_cohort2, function(x) sum(is.na(x)))

```

4. Impute missing values by `miceRanger` (request $m=3$ datasets). This step is very computational intensive. Make sure to save the imputation results as a file.

**Solution**:

No variables were dropped for completeness and out of caution. In order to maximize reproducibility and efficiency, the code for `miceRanger` was wrapped in a conditional statement so that the imputation does not have to be rerun when knitting the code repeatedly. The chunk was wrapped using the chunk option `cache.lazy = FALSE` to help the miceObj load more quickly.

Credit to Benson Wu @benson-wu for troubleshooting this code for me.

```{r load miceObj, cache.lazy = FALSE}


if(file.exists(str_c("./miceObj.RData"))){
  load(str_c("./miceObj.RData"))
} else{
  miceObj <- miceRanger(
    icu_cohort2, m = 3, max.depth = 10, returnModels = T, verbose = F
                         )
  save(miceObj, file = "./miceObj.RData")
}

```


5. Make imputation diagnostic plots and explain what they mean.

**Solution**:

The plot below generated by `plotDistributions()` is a plot of the imputed distributions compared to the original distribution for each numeric variable in the dataset. The red line is the density of the original, non-missing data, and the black lines are the density of the imputed values in each of the 3 datasets. We can see that the distributions of the non-missing data and the imputed values in the 3 datasets match up closely for the variables respiratory rate, temperature (F), calcium, chloride, creatinine, glucose, magnesium, potassium, sodium, hematocrit, and wbc (white blood cell count). The distributions of the non-missing data and imputed values in the 3 data sets do not match up very closely for heart rate, non-invasive systolic blood pressure, non-invasive mean blood pressure, and bicarbonate. The distributions of non-missing and imputed values not matching up may imply that for those variables the data was not missing completely at random (MCAR).

```{r plotDistributions, fig.align = 'center', fig.height=8}
plotDistributions(miceObj, vars = 'allNumeric', ncol = 3, nrow = 5)
```

The boxplots below are boxplots of the correlations between imputed values in every combination of datasets at each iteration. This tells us how values between datasets converged over the iterations.

```{r plotCorrelations, fig.align = 'center', fig.height=8}
plotCorrelations(miceObj, vars = 'allNumeric')
```

The plots below show whether the imputed data converged or if more iterations are needed for convergence. Overall, we do not observe any major sign indicating that the imputed data did not converge, so we do not need to run additional iterations for our data.

```{r plotVarConvergence, fig.align = 'center', fig.height=8}
plotVarConvergence(miceObj, vars = 'allNumeric')
```

Below the plots returns the OOB R^2^ for regression for each dataset and each iteration. We see that variables were not necessarily imputed with a reasonable degree of accuracy, since the R^2^ does not converge with a high degree of accuracy even towards the later iterations for many of the numeric variables.

```{r plotModelError, fig.align = 'center', fig.height=8}
plotModelError(miceObj, vars = 'allNumeric')
```

The plotted variable importance graph shows the importance of variables for each imputed variable. The left axis refers to the imputed variable and the top axis refers to the variable used for imputation.

```{r plotVarImportance, fig.align = 'center', fig.width=10}
plotVarImportance(miceObj, 
                  tl.cex = 0.7, 
                  cl.cex = 0.7, cl.ratio = 0.1, cl.align.text = "l", 
                  number.cex = 0.5)
```

Below the variance experienced for each imputed value between the datasets are visualized below using `plotImputationVariance()`. For numeric variables, the `Q` at the top of each graph refers to the quantile of samples with a SD of imputed values below the population SD. Most numeric variables had quantiles at around or above Q=70.

```{r plotImputationVariance, fig.align = 'center', fig.width = 12}
plotImputationVariance(miceObj, vars='allNumeric')

plotImputationVariance(miceObj, vars='allCategorical')
```



6. Obtain a complete data set by averaging the 3 imputed data sets.

**Solution**:

I obtained the 3 imputed data sets by using the `completeData` function from the miceRanger package. I filtered out only the relevant columns for the predictive analysis of 30-day mortality in Question 2. This included subject id, gender, admitage, martial status, ethnicity, and laboratory measurements and vital signs kept for the imputations. If columns were characters, they were coerced to factors utilizing `mutate_if` and base R, and then coerced to numeric utilizing `mutate_if` and base R again. To average the three imputed data sets to get a complete data set, I utilized code from StackExchange 
[1]: https://stackoverflow.com/questions/31465415/combine-multiple-data-frames-and-calculate-average as reference.

```{r averaging imputed datasets}

imputedList <- completeData(miceObj)

keep <- c("subject_id", "gender", "admitage", "marital_status", "ethnicity",
         "bicarbonate", "calcium", "chloride", "creatinine", "glucose",
         "magnesium", "potassium", "sodium", "hematocrit", "wbc",
         "heart_rate", "non_invasive_blood_pressure_systolic",
         "non_invasive_blood_pressure_mean", "respiratory_rate",
         "temperature_fahrenheit", "mortality30")

dataset1 <- imputedList$Dataset_1[, ..keep, drop=F]
dataset2 <- imputedList$Dataset_2[, ..keep, drop=F]
dataset3 <- imputedList$Dataset_3[, ..keep, drop=F]

dataset1 <- dataset1 %>%  mutate_if(is.character, as.factor) 
dataset2 <- dataset2 %>% mutate_if(is.character, as.factor)
dataset3 <- dataset3 %>%  mutate_if(is.character, as.factor)

# Factors: gender, marital_status, ethnicity, mortality30

dataset1.num <- dataset1 %>% mutate_if(is.factor, as.numeric)
dataset2.num <- dataset2 %>% mutate_if(is.factor, as.numeric)
dataset3.num <- dataset3 %>% mutate_if(is.factor, as.numeric)

## Levels after converting from factor to numeric
# gender:         1 = F
#                 2 = M

# marital_status: 1 = DIVORCED 
#                 2 = SINGLE 
#                 3 = MARRIED 
#                 4 = WIDOWED

# ethnicity:      1 = AMERICAN INDIAN/ALASKA NATIVE,
#                 2 = ASIAN
#                 3 = BLACK/AFRICAN AMERICAN 
#                 4 = HISPANIC/LATINO
#                 5 = OTHER
#                 6 = UNABLE TO OBTAIN
#                 7 = UNKNOWN
#                 8 = WHITE

# mortality30:    1 = Died
#                 2 = Survived

complete.dataset <- rbindlist(list(dataset1.num, dataset2.num, dataset3.num
                                   ))[,lapply(.SD,mean),list(subject_id)]

# turn 2 of 4 factors back into factors (marital_status has a decimal, 
# and mortality30 needs to remain as binary numeric for glm)

factors <- c("gender", "ethnicity")

complete.dataset <- complete.dataset %>% 
  mutate_at(factors, as.factor) %>% 
  # recode mortality30 to 0: survived, 1: died
  mutate(mortality30 = ifelse(mortality30 == 2, 0, mortality30)) %>% 
  # recode gender to descriptive names
  mutate(gender = ifelse(gender == 2, 'Male', 'Female')) %>% 
  # recode ethnicity to descriptive names
  mutate(ethnicity = fct_recode(ethnicity, 
                                "American Indian/Alaska Native" = "1",
                                "Asian" = "2",
                                "Black/African American" = "3",
                                "Hispanic/Latino" = "4",
                                "Other" = "5",
                                "Unable to Obtain" = "6",
                                "Unknown" = "7",
                                "White" = "8"))



```

## Q2. Predicting 30-day mortality

Develop at least two analytic approaches for predicting the 30-day mortality of patients admitted to ICU using demographic information (gender, age, marital status, ethnicity), first lab measurements during ICU stay, and first vital measurements during ICU stay. For example, you can use (1) logistic regression (`glm()` function), (2) logistic regression with lasso penalty (glmnet package), (3) random forest (randomForest package), or (4) neural network.

1. Partition data into 80% training set and 20% test set. Stratify partitioning according the 30-day mortality status.

```{r stratify partitioning}

mimicdata <- complete.dataset %>% mutate(subject_id = NULL)

set.seed(203)
inds <- partition(mimicdata$mortality30, 
                  p = c(train = 0.8, test = 0.2))

train <- mimicdata[inds$train, ]
test  <- mimicdata[inds$test, ]

```


2. Train the models using the training set.

For logistic regression, I received some advice from this page: 
[2]: http://www.sthda.com/english/articles/36-classification-methods-essentials/149-penalized-logistic-regression-essentials-in-r-ridge-lasso-and-elastic-net/#compute-the-full-logistic-model

The full logistic regression model used all 19 predictors and had an AIC of 21410, while the stepwise logistic regression model used only 13 predictors and had an AIC of 21400.

```{r logistic regression train, message=F, warning = F}

# full logistic regression model

full.glm <- glm(mortality30 ~ .,
            family = "binomial",
            data = train)

print(full.glm)


# stepwise selection of logistic regression model

library(MASS)
library(car)
library(caret)

step.glm <- full.glm %>% stepAIC(trace = F)

print(step.glm)

```

For random forest, I converted the outcome variable back to a factor in order for the random forest function to run. I ran a classification random forest with 500 trees and 4 variables tried at each split.

```{r random forest train, cache.lazy = FALSE}

train <- train %>% mutate(mortality30 = as.factor(mortality30))

if(file.exists("./full.rf.RData")){
  load("./full.rf.RData")
} else{
  set.seed(203)
  full.rf <- randomForest(mortality30 ~ ., data = train, importance = T,
                        replace = T)
  save(full.rf, file = "./full.rf.RData")
}

print(full.rf)

```

3. Compare model prediction performance on the test set.

The prediction model for 30-day mortality using the full logistic regression model had an accuracy rate of 90.7%, an error rate of 9.34%, a sensitivity of 9.18%, and a specificity of 99.4%. The prediction model for 30-day mortality using the stepwise logistic regression model had an accuracy rate of 90.6%, an error rate of 9.36%, a sensitivity of 8.77%, and a specificity of 99.4%. The stepwise model is preferred over the full model due to the lower number of predictors used (13 vs. 19), thus simplifying the model.

```{r logistic regression performance}


# FULL MODEL

glmprobabilities <- full.glm %>% predict(test, type = "response")

predicted.classes <- ifelse(glmprobabilities > 0.5, 1, 0)
observed.classes <- test$mortality30

# confusion matrix from full logistic regression model
glmtable <- table(predicted.classes, observed.classes)
colnames(glmtable) <- c('Survived', 'Died')
rownames(glmtable) <- c('Survived', 'Died')
print(glmtable)

# full model accuracy
(glmaccuracy <- mean(predicted.classes == observed.classes))

# full model error rate
(glmerror <- 1 - sum(diag(glmtable))/sum(glmtable))

# full model sensitivity - true deaths over actual deaths
(glmsensitivity <- glmtable[2,2]/sum(glmtable[,2]))


# full model specificity - true survival over actual survival
(glmspecificity <- glmtable[1,1]/sum(glmtable[,1]))


# STEPWISE MODEL

stepprobabilities <- step.glm %>% predict(test, type = "response")

step.predicted.classes <- ifelse(stepprobabilities > 0.5, 1, 0)
observed.classes <- test$mortality30

# confusion matrix from stepwise logistic regression model
steptable <- table(step.predicted.classes, observed.classes)
colnames(steptable) <- c('Survived', 'Died')
rownames(steptable) <- c('Survived', 'Died')
print(steptable)

# stepwise model accuracy
(stepaccuracy <- mean(step.predicted.classes == observed.classes))

# stepwise model error rate
(steperror <- 1 - sum(diag(steptable))/sum(steptable))

# stepwise model sensitivity - true deaths over actual deaths
(stepsensitivity <- steptable[2,2]/sum(steptable[,2]))

# stepwise model specificity - true survival over actual survival
(stepspecificity <- steptable[1,1]/sum(steptable[,1]))



```


The prediction model of 30-day mortality using random forests had an accuracy rate of 91.1%, an error rate of 8.94%, a sensitivity of 10.1%, and a specificity of 99.7%.The performance of the random forest model was slightly better than both logistic regression models. Both models suffer from low sensitivity, which is most likely due to the very low number of participants in the study sample that actually died within 30 days of admission.


```{r random forest performance}

test <- test %>% mutate(mortality30 = as.factor(mortality30))

predicted.rf <- full.rf %>% predict(test, type = "response")

observed.rf <- test$mortality30

# confusion matrix for random forests model
rftable <- table(predicted.rf, observed.rf)
colnames(rftable) <- c('Survived', 'Died')
rownames(rftable) <- c('Survived', 'Died')
print(rftable)

# random forest model accuracy
(rfaccuracy <- sum(predicted.rf == observed.rf) / length(observed.rf))

# random forest model error rate
(rferror <- 1 - sum(diag(rftable))/sum(rftable))

# random forest model sensitivity - true deaths over actual deaths
(rfsensitivity <- rftable[2,2]/sum(rftable[,2]))


# random forest model specificity - true survival over actual survival
(rfspecificity <- rftable[1,1]/sum(rftable[,1]))

```

