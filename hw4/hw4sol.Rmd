---
title: "Biostat 203B Homework 4"
subtitle: Due Mar 12 @ 11:59PM
output:
  html_document:
    toc: true
    toc_depth: 4
  # ioslides_presentation: default
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```
                      
Display machine information:

```{r}
sessionInfo()
```

Load database libraries and the tidyverse frontend:

```{r, echo = T, include = F, eval = T}

library(tidyverse)
library(lubridate)
library(miceRanger)
library(data.table)
library(splitTools)
library(ranger)
library(Metrics)

```

## Q1. Missing data

Through the Shiny app developed in HW3, we observe abundant missing values in the MIMIC-IV ICU cohort we created. In this question, we use multiple imputation to obtain a data set without missing values.

0. Read following tutorials on the R package miceRanger for imputation: <https://github.com/farrellday/miceRanger>, <https://cran.r-project.org/web/packages/miceRanger/vignettes/miceAlgorithm.html>.

    A more thorough book treatment of the practical imputation strategies is the book [*_Flexible Imputation of Missing Data_*](https://stefvanbuuren.name/fimd/) by Stef van Buuren. 

1. Explain the jargon MCAR, MAR, and MNAR.

**Solution**:

MCAR stands for Missing Completely At Random. A variable is missing completely at random if neither the variables in the dataset nor the unobserved value of the variable itself predict whether a value will be missing. In other words, the causes of missing data are unrelated to the data.

MAR stands for Missing at Random. A variable is missing at random if other variables in the dataset can be used to predict the missingness of the variable. In other words, the probability of missingness is the same only within groups defined by the observed data. Most modern missing data methods start from the MAR assumption.

MNAR stands for Missing Not at Random. A variable is missing not at random if the value of the unobserved variable itself predicts missingness. MNAR is the most complex case as the causes for the missingness vary for reasons unknown to the investigator.


2. Explain in a couple of sentences how the Multiple Imputation by Chained Equations (MICE) work.

**Solution**:

Multiple Imputation by Chained Equations (MICE) works by creating multiple imputations to account for statistical uncertainty in the imputations, and utilizing a chained equations approach to allow for flexibility with handling variables of different types. Using the MICE technique assumes that for the variables used in the imputation procedure, the missing data are MAR. If this assumption is not met, then there could be biased estimates when MICE is implemented.

The chained equation process involves 1) an imputation performed for every missing value in the data set, 2) placeholder imputations for one variable are set back to missing, 3) observed values from that one variable are regressed on other variables in the data set, with the one variable as the outcome variable, 4) missing values for that one variable are replaced with the imputations from the regression model if it is used as an outcome, and both observed and imputed values will be used if the variable is used as a predictor. The process is repeated for all the variables to complete one iteration/cycle. For later cycles, imputations are updated at each subsequent cycle. The accuracy of the imputations depends on the information density in the dataset. A dataset of completely independent variables with no correlation will not yield accurate imputations.


3. Perform a data quality check of the ICU stays data. Discard variables with substantial missingness, say >5000 `NA`s. Replace apparent data entry errors by `NA`s.

**Solution**:

```{r Q3 data quality check}
icu_cohort <- readRDS("./icu_cohort.rds")

sapply(icu_cohort, function(x) sum(is.na(x)))

# discarding variables with substantial missingness
icu_cohort2 <- icu_cohort %>% 
  select(-deathtime, -edregtime, -edouttime, -dod, 
         -arterial_blood_pressure_systolic, -arterial_blood_pressure_mean,
         -lactate)


```
I utilized sapply to identify missing values and distribution of values in the dataset. This allowed to identify patients with abnormal values such as a heart rate of 0 when the patient survived and had normal bp measurements for the other columns. I re-ran these built-in functions as necessary to identify data entry errors and filtered them out in the subsequent code chunk.

```{r Q3 unique values, eval = F}

sapply(icu_cohort2[,4:5], unique)
sapply(icu_cohort2[,11:19], unique)
sapply(icu_cohort2[,24:38], unique)
sapply(icu_cohort2[,24:38], summary)
```
Here, I filter out apparent data entry errors. I remained fairly conservative in my removal of abnormal data values, and primarily focused on 0s in the data when other columns appeared to have normal values, and also focused on possible scale conversion errors with Fahrenheit/Celsius that may have been recorded under the Fahrenheit column of the original data set.

```{r Q3 replacement of apparent data entry errors}

# replace 0s with NAs for heart rate, non invasive bp (systolic and mean),
# respiratory rate, temperature in Fahrenheit
icu_cohort2[, 24:28][icu_cohort2[, 24:28] == 0] = NA

# replace 0s with NAs for calcium, creatinine, magnesium, and wbc
icu_cohort2$calcium[icu_cohort2$calcium == 0] = NA
icu_cohort2$creatinine[icu_cohort2$creatinine == 0] = NA
icu_cohort2$magnesium[icu_cohort2$magnesium == 0] = NA
icu_cohort2$wbc[icu_cohort2$wbc == 0] = NA


# replace with NA if blood pressure values were less than 2
icu_cohort2[, 25:26][icu_cohort2[, 25:26] < 2] = NA

# replace with NA if blood pressure values were substantially abnormal
icu_cohort2 <- icu_cohort2 %>% 
  mutate(non_invasive_blood_pressure_systolic = ifelse(
      (non_invasive_blood_pressure_systolic > 300) | 
        (non_invasive_blood_pressure_systolic < 10), NA, 
      non_invasive_blood_pressure_systolic),
    non_invasive_blood_pressure_mean = ifelse(
      non_invasive_blood_pressure_mean > 300 | 
        (non_invasive_blood_pressure_mean < 10), NA,
      non_invasive_blood_pressure_mean),
    # replace with NA if heart rate values were substantially abnormal
    heart_rate = ifelse(heart_rate > 300, NA, heart_rate)
  )


# replace with NA if temperature in Fahrenheit was less than 60
icu_cohort2$temperature_fahrenheit[icu_cohort2$temperature_fahrenheit < 60] = NA

# Check NAs
sapply(icu_cohort2, function(x) sum(is.na(x)))

```

4. Impute missing values by `miceRanger` (request $m=3$ datasets). This step is very computational intensive. Make sure to save the imputation results as a file.

**Solution**:

Credit to Benson Wu @benson-wu for troubleshooting this code for me.

```{r load miceObj, cache.lazy = FALSE}


if(file.exists(str_c("./miceObj.RData"))){
  load(str_c("./miceObj.RData"))
} else{
  miceObj <- miceRanger(
    icu_cohort2, m = 3, max.depth = 10, returnModels = T, verbose = F
                         )
  save(miceObj, file = "./miceObj.RData")
}

```


5. Make imputation diagnostic plots and explain what they mean.

**Solution**:

The plot below generated by `plotDistributions()` is a plot of the imputed distributions compared to the original distribution for each numeric variable in the dataset. The red line is the density of the original, non-missing data, and the black lines are the density of the imputed values in each of the 3 datasets. We can see that the distributions of the non-missing data and the imputed values in the 3 datasets match up closely for the variables respiratory rate, temperature (F), calcium, chloride, creatinine, glucose, magnesium, potassium, sodium, hematocrit, and wbc (white blood cell count). The distributions of the non-missing data and imputed values in the 3 data sets do not match up very closely for heart rate, non-invasive systolic blood pressure, non-invasive mean blood pressure, and bicarbonate. The distributions of non-missing and imputed values not matching up may imply that for those variables the data was not missing completely at random (MCAR).

```{r plotDistributions, fig.align = 'center', fig.height=8}
plotDistributions(miceObj, vars = 'allNumeric', ncol = 3, nrow = 5)
```


```{r plotCorrelations, fig.align = 'center', fig.height=8}
plotCorrelations(miceObj, vars = 'allNumeric')
```


```{r plotVarConvergence, fig.align = 'center', fig.height=8}
plotVarConvergence(miceObj, vars = 'allNumeric')
```


```{r plotModelError, fig.align = 'center', fig.height=8}
plotModelError(miceObj, vars = 'allNumeric')
```


```{r plotVarImportance, fig.align = 'center', fig.width=10}
plotVarImportance(miceObj, 
                  tl.cex = 0.7, 
                  cl.cex = 0.7, cl.ratio = 0.1, cl.align.text = "l", 
                  number.cex = 0.5)
```


```{r plotImputationVariance, fig.align = 'center', fig.width = 12}
plotImputationVariance(miceObj, vars='allNumeric')

plotImputationVariance(miceObj, vars='allCategorical')
```




6. Obtain a complete data set by averaging the 3 imputed data sets.

**Solution**:

I obtained the 3 imputed data sets by using the `completeData` function from the miceRanger package. I filtered out only the relevant columns for the predictive analysis of 30-day mortality in Question 2. This included subject id, gender, admitage, martial status, ethnicity, and laboratory measurements and vital signs kept for the imputations. If columns were characters, they were coerced to factors utilizing `mutate_if` and base R, and then coerced to numeric utilizing `mutate_if` and base R again. To average the three imputed data sets to get a complete data set, I utilized code from StackExchange [1]: https://stackoverflow.com/questions/31465415/combine-multiple-data-frames-and-calculate-average as reference.

```{r averaging imputed datasets}

imputedList <- completeData(miceObj)

keep <- c("subject_id", "gender", "admitage", "marital_status", "ethnicity",
         "bicarbonate", "calcium", "chloride", "creatinine", "glucose",
         "magnesium", "potassium", "sodium", "hematocrit", "wbc",
         "heart_rate", "non_invasive_blood_pressure_systolic",
         "non_invasive_blood_pressure_mean", "respiratory_rate",
         "temperature_fahrenheit", "mortality30")

dataset1 <- imputedList$Dataset_1[, ..keep, drop=F]
dataset2 <- imputedList$Dataset_2[, ..keep, drop=F]
dataset3 <- imputedList$Dataset_3[, ..keep, drop=F]

dataset1 <- dataset1 %>%  mutate_if(is.character, as.factor) 
dataset2 <- dataset2 %>% mutate_if(is.character, as.factor)
dataset3 <- dataset3 %>%  mutate_if(is.character, as.factor)

# Factors: gender, marital_status, ethnicity, mortality30

dataset1.num <- dataset1 %>% mutate_if(is.factor, as.numeric)
dataset2.num <- dataset2 %>% mutate_if(is.factor, as.numeric)
dataset3.num <- dataset3 %>% mutate_if(is.factor, as.numeric)

## Levels after converting from factor to numeric
# gender:         1 = F
#                 2 = M

# marital_status: 1 = DIVORCED 
#                 2 = SINGLE 
#                 3 = MARRIED 
#                 4 = WIDOWED

# ethnicity:      1 = AMERICAN INDIAN/ALASKA NATIVE,
#                 2 = ASIAN
#                 3 = BLACK/AFRICAN AMERICAN 
#                 4 = HISPANIC/LATINO
#                 5 = OTHER
#                 6 = UNABLE TO OBTAIN
#                 7 = UNKNOWN
#                 8 = WHITE

# mortality30:    1 = Died
#                 2 = Survived

complete.dataset <- rbindlist(list(dataset1.num, dataset2.num, dataset3.num
                                   ))[,lapply(.SD,mean),list(subject_id)]

# turn 2 of 4 factors back into factors (marital_status has a decimal, 
# and mortality30 needs to remain as binary numeric for glm)

factors <- c("gender", "ethnicity")

complete.dataset <- complete.dataset %>% 
  mutate_at(factors, as.factor) %>% 
  # recode mortality30 to 0: survived, 1: died
  mutate(mortality30 = ifelse(mortality30 == 2, 0, mortality30)) %>% 
  # recode gender to descriptive names
  mutate(gender = ifelse(gender == 2, 'Male', 'Female')) %>% 
  # recode ethnicity to descriptive names
  mutate(ethnicity = fct_recode(ethnicity, 
                                "American Indian/Alaska Native" = "1",
                                "Asian" = "2",
                                "Black/African American" = "3",
                                "Hispanic/Latino" = "4",
                                "Other" = "5",
                                "Unable to Obtain" = "6",
                                "Unknown" = "7",
                                "White" = "8"))



```

## Q2. Predicting 30-day mortality

Develop at least two analytic approaches for predicting the 30-day mortality of patients admitted to ICU using demographic information (gender, age, marital status, ethnicity), first lab measurements during ICU stay, and first vital measurements during ICU stay. For example, you can use (1) logistic regression (`glm()` function), (2) logistic regression with lasso penalty (glmnet package), (3) random forest (randomForest package), or (4) neural network.

1. Partition data into 80% training set and 20% test set. Stratify partitioning according the 30-day mortality status.

```{r stratify partitioning}

set.seed(203)
inds <- partition(complete.dataset$mortality30, 
                  p = c(train = 0.8, test = 0.2))

train <- complete.dataset[inds$train, ]
test  <- complete.dataset[inds$test, ]

```


2. Train the models using the training set.
```{r logistic regression}

#this is the model this is not training

glm1 <- glm(mortality30 ~ gender + marital_status + ethnicity + admitage +
              bicarbonate + calcium + chloride + creatinine + glucose + 
              magnesium + potassium + sodium + hematocrit + wbc + heart_rate +
              non_invasive_blood_pressure_systolic + 
              non_invasive_blood_pressure_mean + 
              respiratory_rate + temperature_fahrenheit, 
            family = "binomial",
            data = complete.dataset)

summary(glm1)

```

```{r}

```

3. Compare model prediction performance on the test set.

